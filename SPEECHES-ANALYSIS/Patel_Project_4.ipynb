{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patel_Project_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 4"
      ],
      "metadata": {
        "id": "ZHAJar1bP4Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Jemil Patel\n",
        "\n",
        "!pip install readability # installing readability package\n",
        "\n",
        "# required imports used in the program\n",
        "import operator\n",
        "import readability\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def strip_punctuations(words): # accepts a list of words and returns an updated list after removing punctuations from before and after each word\n",
        "    \n",
        "  new_words = []\n",
        "\n",
        "  for word in words:\n",
        "\n",
        "    start = 0\n",
        "    end = 0\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    # by the end of this loop we will get the first occurence of any letter inside a word\n",
        "    while index < len(word): \n",
        "      if word[index].isalpha() or word[index].isdigit():\n",
        "        start = index\n",
        "        break\n",
        "      index += 1\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    # by the end of this loop we will get the last occurence of any letter inside a word\n",
        "    while index < len(word):\n",
        "      if word[index].isalpha() or word[index].isdigit():\n",
        "        end = index\n",
        "      index += 1\n",
        "\n",
        "    new_words.append(word[start:end+1]) # appending the updated word to the new list\n",
        "    \n",
        "  return new_words\n",
        "\n",
        "def average_word_length(words): # accepts a list of words and returns the average length of a word\n",
        "\n",
        "  sum = 0\n",
        "\n",
        "  for word in words:\n",
        "    sum += len(word)\n",
        "\n",
        "  return sum / len(words)\n",
        "\n",
        "def word_frequency(words): # accepts a list of words and returns a dictionary with (word, frequency) pair sorted in descending order by frequency\n",
        "\n",
        "  freq = dict()\n",
        "\n",
        "  for word in words:\n",
        "    if word.lower() != 'a' and word.lower() != 'an' and word.lower() != 'the' and word.lower() != 'and': # 'a', 'an', 'the', 'and' are not allowed\n",
        "      if word.lower() not in freq:\n",
        "        freq[word.lower()] = 1\n",
        "      else:\n",
        "        freq[word.lower()] += 1\n",
        "\n",
        "  sorted_freq = dict(sorted(freq.items(), key=operator.itemgetter(1), reverse=True)) # creating a new dictionary by sorting the original one via descending order of frequency\n",
        "\n",
        "  return sorted_freq\n",
        "\n",
        "def word_length(words): # accepts a list of words and returns a dictionary with (word, length) pair sorted in descending order by length\n",
        "\n",
        "  lengths = dict()\n",
        "\n",
        "  for word in words:\n",
        "    if word.lower() not in lengths:\n",
        "      lengths[word.lower()] = len(word.lower())\n",
        "\n",
        "  sorted_lengths = dict(sorted(lengths.items(), key=operator.itemgetter(1), reverse=True)) # creating a new dictionary by sorting the original one via descending order of length\n",
        "\n",
        "  return sorted_lengths\n",
        "\n",
        "def number_of_sentences(words): # accepts a text or a list of words and returns the number of sentences present\n",
        "\n",
        "  sentences = 0\n",
        "\n",
        "  for line in words:\n",
        "    if '.' in line or '?' in line or '!' in line:\n",
        "      sentences += 1\n",
        "\n",
        "  return sentences\n",
        "\n",
        "print()\n",
        "\n",
        "while True:\n",
        "  name = input('Enter a valid filename (with extension): ')\n",
        "  try:\n",
        "    speech = open(name, 'r')\n",
        "  except FileNotFoundError:\n",
        "    print('No such file found! Please try again')\n",
        "    continue\n",
        "  break\n",
        "\n",
        "words = []\n",
        "\n",
        "# extracting words from the text file\n",
        "for line in speech:\n",
        "  for word in line.split():\n",
        "    words.append(word)\n",
        "\n",
        "speech.close()\n",
        "\n",
        "# Declaring and initializing necessary variables\n",
        "\n",
        "word_count = len(words)\n",
        "sentence_count = number_of_sentences(words)\n",
        "\n",
        "words = strip_punctuations(words)\n",
        "\n",
        "avg_word = average_word_length(words)\n",
        "avg_sentence = word_count / sentence_count\n",
        "\n",
        "word_freq = word_frequency(words)\n",
        "word_len = word_length(words)\n",
        "\n",
        "print('\\n-------------------------MY CALCULATIONS-------------------------')\n",
        "\n",
        "print(f'Total word count : {word_count}')\n",
        "print(f'Total sentence count : {sentence_count}\\n')\n",
        "\n",
        "print(f'Average letters per word : {avg_word}')\n",
        "print(f'Average words per sentence : {avg_sentence}\\n')\n",
        "\n",
        "print('15 most frequently used words are (in descending order)')\n",
        "x = 0\n",
        "for k,v in word_freq.items():\n",
        "  if x == 15:\n",
        "    break\n",
        "  print(f'{k} : {v} occurences')\n",
        "  x += 1\n",
        "\n",
        "print('\\n10 longest words are (in ascending order)')\n",
        "x = 0\n",
        "keys = []\n",
        "for k,v in word_len.items():\n",
        "  if x == 15:\n",
        "    break\n",
        "  if k.isalpha(): # to check if the word does not contain any special character\n",
        "    keys.append(k)\n",
        "    x += 1\n",
        "keys.reverse() # to help print the longest words in ascending order\n",
        "for k in keys:\n",
        "  print(f'{k} : {word_len[k]} letters')\n",
        "\n",
        "print('\\n---------------------------READABILITY---------------------------')\n",
        "\n",
        "speech = open(name, 'r')\n",
        "text = ''\n",
        "\n",
        "for line in speech:\n",
        "  text += line\n",
        "\n",
        "results = readability.getmeasures(text) # storing the readability results in a variable\n",
        "\n",
        "for x in results:\n",
        "  print(f'{x} :')\n",
        "  for y in results[x]:\n",
        "    print(f'    {y} : {results[x][y]}')\n",
        "\n",
        "speech.close()\n",
        "\n",
        "print('\\n----------------------------WORD CLOUD---------------------------')\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate_from_frequencies(word_freq) # creating a word cloud based on the frequency of each word\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "wordcloud.to_file(\"patel_wordcloud.png\") # saving the word cloud as a png file"
      ],
      "metadata": {
        "id": "iz4q_t4JP5zg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}